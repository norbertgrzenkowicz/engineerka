{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.178624</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.010825</td>\n",
       "      <td>07:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.054948</td>\n",
       "      <td>0.037453</td>\n",
       "      <td>0.009472</td>\n",
       "      <td>10:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PDF CONVERT\n",
    "#\n",
    "# jupyter-nbconvert --to PDFviaHTML example.ipynb\n",
    "\n",
    "\n",
    "#id first_training\n",
    "#caption Results from the first training\n",
    "# CLICK ME\n",
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "\n",
    "def is_cat(x): return x[0].isupper()\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PILImage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/norbert/Documents/repos/engineerka/jupyter/~/pytorch_time.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/norbert/Documents/repos/engineerka/jupyter/~/pytorch_time.ipynb#ch0000001?line=0'>1</a>\u001b[0m img \u001b[39m=\u001b[39m PILImage\u001b[39m.\u001b[39mcreate(image_cat())\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/norbert/Documents/repos/engineerka/jupyter/~/pytorch_time.ipynb#ch0000001?line=1'>2</a>\u001b[0m img\u001b[39m.\u001b[39mto_thumb(\u001b[39m192\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PILImage' is not defined"
     ]
    }
   ],
   "source": [
    "img = PILImage.create(image_cat())\n",
    "img.to_thumb(192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'widgets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/norbert/Documents/repos/engineerka/jupyter/~/pytorch_time.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/norbert/Documents/repos/engineerka/jupyter/~/pytorch_time.ipynb#ch0000004?line=0'>1</a>\u001b[0m uploader \u001b[39m=\u001b[39m widgets\u001b[39m.\u001b[39mFileUpload()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/norbert/Documents/repos/engineerka/jupyter/~/pytorch_time.ipynb#ch0000004?line=1'>2</a>\u001b[0m uploader\n",
      "\u001b[0;31mNameError\u001b[0m: name 'widgets' is not defined"
     ]
    }
   ],
   "source": [
    "uploader = widgets.FileUpload()\n",
    "uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader = SimpleNamespace(data = ['images/chapter1_cat_example.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'images/chapter1_cat_example.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/norbert/Documents/repos/engineerka/jupyter/~/pytorch_time.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/norbert/Documents/repos/engineerka/jupyter/~/pytorch_time.ipynb#ch0000006?line=0'>1</a>\u001b[0m img \u001b[39m=\u001b[39m PILImage\u001b[39m.\u001b[39;49mcreate(uploader\u001b[39m.\u001b[39;49mdata[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/norbert/Documents/repos/engineerka/jupyter/~/pytorch_time.ipynb#ch0000006?line=1'>2</a>\u001b[0m is_cat,_, probs \u001b[39m=\u001b[39m learn\u001b[39m.\u001b[39mpredict(img)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/norbert/Documents/repos/engineerka/jupyter/~/pytorch_time.ipynb#ch0000006?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIs this a cat?: \u001b[39m\u001b[39m{\u001b[39;00mis_cat\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/repos/engineerka/venv/lib/python3.10/site-packages/fastai/vision/core.py:120\u001b[0m, in \u001b[0;36mPILBase.create\u001b[0;34m(cls, fn, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/fastai/vision/core.py?line=117'>118</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fn,ndarray): \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(Image\u001b[39m.\u001b[39mfromarray(fn))\n\u001b[1;32m    <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/fastai/vision/core.py?line=118'>119</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fn,\u001b[39mbytes\u001b[39m): fn \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(fn)\n\u001b[0;32m--> <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/fastai/vision/core.py?line=119'>120</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(load_image(fn, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmerge(\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_open_args, kwargs)))\n",
      "File \u001b[0;32m~/Documents/repos/engineerka/venv/lib/python3.10/site-packages/fastai/vision/core.py:95\u001b[0m, in \u001b[0;36mload_image\u001b[0;34m(fn, mode)\u001b[0m\n\u001b[1;32m     <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/fastai/vision/core.py?line=92'>93</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_image\u001b[39m(fn, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/fastai/vision/core.py?line=93'>94</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOpen and load a `PIL.Image` and convert to `mode`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/fastai/vision/core.py?line=94'>95</a>\u001b[0m     im \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(fn)\n\u001b[1;32m     <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/fastai/vision/core.py?line=95'>96</a>\u001b[0m     im\u001b[39m.\u001b[39mload()\n\u001b[1;32m     <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/fastai/vision/core.py?line=96'>97</a>\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39m_new(im\u001b[39m.\u001b[39mim)\n",
      "File \u001b[0;32m~/Documents/repos/engineerka/venv/lib/python3.10/site-packages/PIL/Image.py:3068\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/PIL/Image.py?line=3064'>3065</a>\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[1;32m   <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/PIL/Image.py?line=3066'>3067</a>\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/PIL/Image.py?line=3067'>3068</a>\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/PIL/Image.py?line=3068'>3069</a>\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/norbert/Documents/repos/engineerka/venv/lib/python3.10/site-packages/PIL/Image.py?line=3070'>3071</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images/chapter1_cat_example.jpg'"
     ]
    }
   ],
   "source": [
    "img = PILImage.create(uploader.data[0])\n",
    "is_cat,_, probs = learn.predict(img)\n",
    "print(f\"Is this a cat?: {is_cat}.\")\n",
    "print(f\"Probability it's a cat: {probs[1].item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d992f389273a7d574fbbfbbfc18aa8d5e70e24f74243bd3ce350b92b3671030"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
